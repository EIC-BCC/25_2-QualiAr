{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7571b76",
   "metadata": {},
   "source": [
    "# EDA — Estação Tijuca (Dados Horários de Qualidade do Ar)\n",
    "\n",
    "Este notebook realiza uma **análise exploratória completa** (EDA) dos dados horários da **Estação Tijuca**,\n",
    "com foco nas variáveis meteorológicas e de poluentes atmosféricos. O fluxo foi desenhado para ser **reutilizável**\n",
    "em outras estações, bastando trocar o caminho do arquivo de entrada.\n",
    "\n",
    "## O que este notebook faz\n",
    "1. **Carregamento e inspeção** do conjunto de dados (tipos, dimensões, faltantes, duplicados).\n",
    "2. **Tratamento de datas** e criação de colunas temporais (dia, mês, ano).\n",
    "3. **Regra de imputação condicional** (baseada em boas práticas WMO/WHO):\n",
    "   - Se **≤4 horas faltantes dentro do mesmo dia** → interpolar por dia (por variável).\n",
    "   - Se **>4 horas** → manter **NaN** (evita viés em lacunas longas).\n",
    "4. **Checagens de plausibilidade física** e marcação/remoção de outliers extremos.\n",
    "5. **Estatísticas descritivas** por variável (média, mediana, quantis, etc.).\n",
    "6. **Sazonalidade e tendência** (médias mensais/anuais, médias móveis).\n",
    "7. **Distribuições** (histogramas e boxplots).\n",
    "8. **Correlação** entre variáveis.\n",
    "9. **Exporta** dados limpos e resumos (CSV) + **figuras** em pasta própria da estação.\n",
    "\n",
    "> **Base científica para a regra de imputação**  \n",
    "> - **WMO (2021)** e **WHO (2021)** recomendam evitar interpolação em **lacunas longas**, usando-a apenas para **pequenos hiatos** (algumas horas).  \n",
    "> - Estudos (e.g., Vicedo‑Cabrera et al., *Environmental Research*, 2018) mostram que imputações inadequadas podem **subestimar picos** e **enviesar análises** associadas a saúde.\n",
    "\n",
    "> **Entrada esperada**: um CSV com colunas como `nome_estacao`, `data`, `chuva`, `temp`, `ur`, `co`, `no`, `no2`, `nox`, `so2`, `o3`, `pm10`, `pm2_5`, `lat`, `lon`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce368f50",
   "metadata": {},
   "source": [
    "## Configurações e importações\n",
    "Bibliotecas usadas e parâmetros gerais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc4e1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando arquivo: https://raw.githubusercontent.com/EIC-BCC/25_2-QualiAr/refs/heads/main/data/DataRio/Estacoes/ESTACAO_TIJUCA.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path as _Path\n",
    "\n",
    "# Pastas de saída\n",
    "ESTACAO = \"TIJUCA\"\n",
    "OUT_BASE = Path(f\"resultados_estacao_{ESTACAO}\")\n",
    "FIG_DIR = OUT_BASE / \"figuras\"\n",
    "DATA_DIR = OUT_BASE / \"dados\"\n",
    "OUT_BASE.mkdir(exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR = _Path(f\"resultados_estacao_{ESTACAO}\") / \"dados\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR = _Path(f\"resultados_estacao_{ESTACAO}\") / \"figuras\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INPUT_PATH = 'https://raw.githubusercontent.com/EIC-BCC/25_2-QualiAr/refs/heads/main/data/DataRio/Estacoes/ESTACAO_TIJUCA.csv'\n",
    "\n",
    "print(\"Usando arquivo:\", INPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72677296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper para criar uma pasta por coluna \n",
    "def _col_dir(base_dir, col_name):\n",
    "    safe = str(col_name).strip().lower().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    d = base_dir / safe\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca111bc1",
   "metadata": {},
   "source": [
    "## Carregamento e inspeção inicial\n",
    "Verificamos dimensões, tipos, amostras, faltantes e duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "583fa789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões: (113976, 23)\n",
      "\n",
      "Tipos:\n",
      "nome_estacao       object\n",
      "codnum              int64\n",
      "data               object\n",
      "chuva             float64\n",
      "temp              float64\n",
      "ur                float64\n",
      "pres              float64\n",
      "rs                float64\n",
      "dir_vento         float64\n",
      "vel_vento         float64\n",
      "co                float64\n",
      "no                float64\n",
      "no2               float64\n",
      "nox               float64\n",
      "so2               float64\n",
      "o3                float64\n",
      "pm10              float64\n",
      "pm2_5             float64\n",
      "lat               float64\n",
      "lon               float64\n",
      "data_formatada     object\n",
      "ano                 int64\n",
      "mes                 int64\n",
      "dtype: object\n",
      "\n",
      "Amostra:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome_estacao</th>\n",
       "      <th>codnum</th>\n",
       "      <th>data</th>\n",
       "      <th>chuva</th>\n",
       "      <th>temp</th>\n",
       "      <th>ur</th>\n",
       "      <th>pres</th>\n",
       "      <th>rs</th>\n",
       "      <th>dir_vento</th>\n",
       "      <th>vel_vento</th>\n",
       "      <th>...</th>\n",
       "      <th>nox</th>\n",
       "      <th>so2</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>data_formatada</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 00:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.62</td>\n",
       "      <td>88.31</td>\n",
       "      <td>1007.32</td>\n",
       "      <td>12.88</td>\n",
       "      <td>216.50</td>\n",
       "      <td>2.28</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "      <td>24.71</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 01:30:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>23.50</td>\n",
       "      <td>93.05</td>\n",
       "      <td>1008.05</td>\n",
       "      <td>11.35</td>\n",
       "      <td>217.00</td>\n",
       "      <td>1.65</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 02:30:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.51</td>\n",
       "      <td>98.06</td>\n",
       "      <td>1008.63</td>\n",
       "      <td>11.20</td>\n",
       "      <td>197.83</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>19.22</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 03:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>98.40</td>\n",
       "      <td>1007.10</td>\n",
       "      <td>11.15</td>\n",
       "      <td>194.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.51</td>\n",
       "      <td>24.55</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 04:30:00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21.36</td>\n",
       "      <td>98.41</td>\n",
       "      <td>1006.13</td>\n",
       "      <td>11.08</td>\n",
       "      <td>193.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>19.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     nome_estacao  codnum                 data  chuva   temp     ur     pres  \\\n",
       "0  ESTAÇÃO TIJUCA       8  2012-01-01 00:30:00    0.0  24.62  88.31  1007.32   \n",
       "1  ESTAÇÃO TIJUCA       8  2012-01-01 01:30:00    0.4  23.50  93.05  1008.05   \n",
       "2  ESTAÇÃO TIJUCA       8  2012-01-01 02:30:00    1.0  22.51  98.06  1008.63   \n",
       "3  ESTAÇÃO TIJUCA       8  2012-01-01 03:30:00    0.0  21.47  98.40  1007.10   \n",
       "4  ESTAÇÃO TIJUCA       8  2012-01-01 04:30:00    0.2  21.36  98.41  1006.13   \n",
       "\n",
       "      rs  dir_vento  vel_vento  ...  nox   so2     o3  pm10  pm2_5        lat  \\\n",
       "0  12.88     216.50       2.28  ...  NaN  0.36  24.71  27.0    NaN -22.924915   \n",
       "1  11.35     217.00       1.65  ...  NaN  0.28  22.74  28.0    NaN -22.924915   \n",
       "2  11.20     197.83       0.58  ...  NaN  0.27  19.22  28.0    NaN -22.924915   \n",
       "3  11.15     194.33       0.00  ...  NaN  1.51  24.55  36.0    NaN -22.924915   \n",
       "4  11.08     193.33       0.00  ...  NaN  1.89  19.00  40.0    NaN -22.924915   \n",
       "\n",
       "         lon  data_formatada   ano  mes  \n",
       "0 -43.232657      2012-01-01  2012    1  \n",
       "1 -43.232657      2012-01-01  2012    1  \n",
       "2 -43.232657      2012-01-01  2012    1  \n",
       "3 -43.232657      2012-01-01  2012    1  \n",
       "4 -43.232657      2012-01-01  2012    1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores ausentes por coluna:\n",
      "nome_estacao           0\n",
      "codnum                 0\n",
      "data                   0\n",
      "chuva               5835\n",
      "temp                6992\n",
      "ur                  7138\n",
      "pres                4541\n",
      "rs                  9071\n",
      "dir_vento          17696\n",
      "vel_vento          17698\n",
      "co                 30987\n",
      "no                 35940\n",
      "no2                35805\n",
      "nox                35784\n",
      "so2                37665\n",
      "o3                 10236\n",
      "pm10                6012\n",
      "pm2_5             113976\n",
      "lat                    0\n",
      "lon                    0\n",
      "data_formatada         0\n",
      "ano                    0\n",
      "mes                    0\n",
      "dtype: int64\n",
      "\n",
      "Registros duplicados por ['nome_estacao', 'data']: 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_PATH)\n",
    "\n",
    "print(\"Dimensões:\", df.shape)\n",
    "print(\"\\nTipos:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nAmostra:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Duplicados (por carimbo horário e nome_estacao, se houver)\n",
    "dup_cols = [c for c in ['nome_estacao', 'data'] if c in df.columns]\n",
    "if dup_cols:\n",
    "    ndup = df.duplicated(subset=dup_cols).sum()\n",
    "    print(f\"\\nRegistros duplicados por {dup_cols}: {ndup}\")\n",
    "else:\n",
    "    print(\"\\nColunas para checar duplicados não disponíveis (nome_estacao/data).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e9f32",
   "metadata": {},
   "source": [
    "## Datas e colunas temporais\n",
    "Converte `data` para `datetime` e cria `dia`, `mes`, `ano` e `data_dia`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214963bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\3424442276.py:3: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['data'] = pd.to_datetime(df['data'], errors='coerce', infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome_estacao</th>\n",
       "      <th>codnum</th>\n",
       "      <th>data</th>\n",
       "      <th>chuva</th>\n",
       "      <th>temp</th>\n",
       "      <th>ur</th>\n",
       "      <th>pres</th>\n",
       "      <th>rs</th>\n",
       "      <th>dir_vento</th>\n",
       "      <th>vel_vento</th>\n",
       "      <th>...</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>data_formatada</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>data_dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 00:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.62</td>\n",
       "      <td>88.31</td>\n",
       "      <td>1007.32</td>\n",
       "      <td>12.88</td>\n",
       "      <td>216.50</td>\n",
       "      <td>2.28</td>\n",
       "      <td>...</td>\n",
       "      <td>24.71</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 01:30:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>23.50</td>\n",
       "      <td>93.05</td>\n",
       "      <td>1008.05</td>\n",
       "      <td>11.35</td>\n",
       "      <td>217.00</td>\n",
       "      <td>1.65</td>\n",
       "      <td>...</td>\n",
       "      <td>22.74</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 02:30:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.51</td>\n",
       "      <td>98.06</td>\n",
       "      <td>1008.63</td>\n",
       "      <td>11.20</td>\n",
       "      <td>197.83</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>19.22</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 03:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>98.40</td>\n",
       "      <td>1007.10</td>\n",
       "      <td>11.15</td>\n",
       "      <td>194.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>24.55</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 04:30:00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21.36</td>\n",
       "      <td>98.41</td>\n",
       "      <td>1006.13</td>\n",
       "      <td>11.08</td>\n",
       "      <td>193.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>19.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     nome_estacao  codnum                data  chuva   temp     ur     pres  \\\n",
       "0  ESTAÇÃO TIJUCA       8 2012-01-01 00:30:00    0.0  24.62  88.31  1007.32   \n",
       "1  ESTAÇÃO TIJUCA       8 2012-01-01 01:30:00    0.4  23.50  93.05  1008.05   \n",
       "2  ESTAÇÃO TIJUCA       8 2012-01-01 02:30:00    1.0  22.51  98.06  1008.63   \n",
       "3  ESTAÇÃO TIJUCA       8 2012-01-01 03:30:00    0.0  21.47  98.40  1007.10   \n",
       "4  ESTAÇÃO TIJUCA       8 2012-01-01 04:30:00    0.2  21.36  98.41  1006.13   \n",
       "\n",
       "      rs  dir_vento  vel_vento  ...     o3  pm10  pm2_5        lat        lon  \\\n",
       "0  12.88     216.50       2.28  ...  24.71  27.0    NaN -22.924915 -43.232657   \n",
       "1  11.35     217.00       1.65  ...  22.74  28.0    NaN -22.924915 -43.232657   \n",
       "2  11.20     197.83       0.58  ...  19.22  28.0    NaN -22.924915 -43.232657   \n",
       "3  11.15     194.33       0.00  ...  24.55  36.0    NaN -22.924915 -43.232657   \n",
       "4  11.08     193.33       0.00  ...  19.00  40.0    NaN -22.924915 -43.232657   \n",
       "\n",
       "   data_formatada   ano  mes  dia    data_dia  \n",
       "0      2012-01-01  2012    1    1  2012-01-01  \n",
       "1      2012-01-01  2012    1    1  2012-01-01  \n",
       "2      2012-01-01  2012    1    1  2012-01-01  \n",
       "3      2012-01-01  2012    1    1  2012-01-01  \n",
       "4      2012-01-01  2012    1    1  2012-01-01  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converte para datetime (ajuste o 'format' se necessário)\n",
    "# Formatos comuns: '%Y-%m-%d %H:%M:%S', '%m/%d/%Y %I:%M:%S %p'\n",
    "df['data'] = pd.to_datetime(df['data'], errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "# Colunas temporais\n",
    "df['ano'] = df['data'].dt.year\n",
    "df['mes'] = df['data'].dt.month\n",
    "df['dia'] = df['data'].dt.day\n",
    "df['data_dia'] = df['data'].dt.date\n",
    "\n",
    "# Ordena cronologicamente\n",
    "df = df.sort_values('data').reset_index(drop=True)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f933385a",
   "metadata": {},
   "source": [
    "## Seleção de colunas e tipos\n",
    "Mantemos apenas as colunas de interesse e garantimos tipos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ecaed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas mantidas: ['nome_estacao', 'codnum', 'data', 'ano', 'mes', 'dia', 'data_dia', 'chuva', 'temp', 'ur', 'co', 'no', 'no2', 'nox', 'so2', 'o3', 'pm10', 'pm2_5', 'lat', 'lon']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome_estacao</th>\n",
       "      <th>codnum</th>\n",
       "      <th>data</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>data_dia</th>\n",
       "      <th>chuva</th>\n",
       "      <th>temp</th>\n",
       "      <th>ur</th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>nox</th>\n",
       "      <th>so2</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 00:30:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.62</td>\n",
       "      <td>88.31</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "      <td>24.71</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 01:30:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>23.50</td>\n",
       "      <td>93.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 02:30:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.51</td>\n",
       "      <td>98.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>19.22</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 03:30:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>98.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.51</td>\n",
       "      <td>24.55</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-01 04:30:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21.36</td>\n",
       "      <td>98.41</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>19.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nome_estacao  codnum                data   ano  mes  dia    data_dia  \\\n",
       "0  ESTAÇÃO TIJUCA       8 2012-01-01 00:30:00  2012    1    1  2012-01-01   \n",
       "1  ESTAÇÃO TIJUCA       8 2012-01-01 01:30:00  2012    1    1  2012-01-01   \n",
       "2  ESTAÇÃO TIJUCA       8 2012-01-01 02:30:00  2012    1    1  2012-01-01   \n",
       "3  ESTAÇÃO TIJUCA       8 2012-01-01 03:30:00  2012    1    1  2012-01-01   \n",
       "4  ESTAÇÃO TIJUCA       8 2012-01-01 04:30:00  2012    1    1  2012-01-01   \n",
       "\n",
       "   chuva   temp     ur    co  no  no2  nox   so2     o3  pm10  pm2_5  \\\n",
       "0    0.0  24.62  88.31  0.07 NaN  NaN  NaN  0.36  24.71  27.0    NaN   \n",
       "1    0.4  23.50  93.05  0.11 NaN  NaN  NaN  0.28  22.74  28.0    NaN   \n",
       "2    1.0  22.51  98.06  0.10 NaN  NaN  NaN  0.27  19.22  28.0    NaN   \n",
       "3    0.0  21.47  98.40  0.06 NaN  NaN  NaN  1.51  24.55  36.0    NaN   \n",
       "4    0.2  21.36  98.41  0.08 NaN  NaN  NaN  1.89  19.00  40.0    NaN   \n",
       "\n",
       "         lat        lon  \n",
       "0 -22.924915 -43.232657  \n",
       "1 -22.924915 -43.232657  \n",
       "2 -22.924915 -43.232657  \n",
       "3 -22.924915 -43.232657  \n",
       "4 -22.924915 -43.232657  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colunas_relevantes = ['nome_estacao', 'codnum', 'data', 'ano', 'mes', 'dia', 'data_dia', 'chuva', 'temp', 'ur', 'co', 'no', 'no2', 'nox', 'so2', 'o3', 'pm10', 'pm2_5', 'lat', 'lon']\n",
    "presentes = [c for c in colunas_relevantes if c in df.columns]\n",
    "df = df[presentes].copy()\n",
    "\n",
    "# Força numérico para variáveis ambientais (ignora erros -> NaN)\n",
    "num_cols = [c for c in ['chuva','temp','ur','co','no','no2','nox','so2','o3','pm10','pm2_5','lat','lon'] if c in df.columns]\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "print(\"Colunas mantidas:\", df.columns.tolist())\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573326e4",
   "metadata": {},
   "source": [
    "## Imputação condicional por dia (≤6 horas)  \n",
    "**Por quê?** Para evitar viés, interpolamos **apenas lacunas curtas** (≤6 horas) dentro de cada dia e variável. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cec3b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_interp = [c for c in ['chuva','temp','ur','co','no','no2','nox','so2','o3','pm10','pm2_5'] if c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b370319a",
   "metadata": {},
   "source": [
    "### Distribuição de valores vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5afdae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_missing_distribution(df_, col, outdir):\n",
    "    if col not in df_.columns:\n",
    "        return\n",
    "\n",
    "    if 'data_dia' not in df_.columns:\n",
    "        df_ = df_.copy()\n",
    "        df_['data'] = pd.to_datetime(df_['data'], errors='coerce', infer_datetime_format=True)\n",
    "        df_['data_dia'] = df_['data'].dt.date\n",
    "\n",
    "    # Contagem de nulos por dia\n",
    "    daily_nans = df_.groupby('data_dia')[col].apply(lambda s: s.isna().sum()).astype(int)\n",
    "\n",
    "    # Histograma excluindo dias sem nulos \n",
    "    x = daily_nans[daily_nans > 0]\n",
    "    if not x.empty:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.hist(x, bins=range(1, int(x.max()) + 2), align='left', edgecolor='black')\n",
    "        plt.title(f'Distribuição de nulos por dia — {col} (dias com > 0 nulos)')\n",
    "        plt.xlabel('Nulos no dia (1–24)')\n",
    "        plt.ylabel('Número de dias')\n",
    "        plt.xticks(range(1, int(x.max()) + 1))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outdir / \"missing_hist.png\", dpi=150)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3591c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols_to_interp:\n",
    "    col_dir = _col_dir(FIG_DIR, c)\n",
    "    plot_missing_distribution(df, c, col_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95915127",
   "metadata": {},
   "source": [
    "### Interpolando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3ef3202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " chuva: valores vazios totais = 5835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - 321 valores imputados em 'chuva' (≈ 5.5% dos nulos iniciais).\n",
      "\n",
      " temp: valores vazios totais = 6992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - 402 valores imputados em 'temp' (≈ 5.7% dos nulos iniciais).\n",
      "\n",
      " ur: valores vazios totais = 7138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - 411 valores imputados em 'ur' (≈ 5.8% dos nulos iniciais).\n",
      "\n",
      " co: valores vazios totais = 30987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - 774 valores imputados em 'co' (≈ 2.5% dos nulos iniciais).\n",
      "\n",
      " no: valores vazios totais = 35940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - 3019 valores imputados em 'no' (≈ 8.4% dos nulos iniciais).\n",
      "\n",
      " no2: valores vazios totais = 35805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - 2996 valores imputados em 'no2' (≈ 8.4% dos nulos iniciais).\n",
      "\n",
      " nox: valores vazios totais = 35784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - 2988 valores imputados em 'nox' (≈ 8.4% dos nulos iniciais).\n",
      "\n",
      " so2: valores vazios totais = 37665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - 4082 valores imputados em 'so2' (≈ 10.8% dos nulos iniciais).\n",
      "\n",
      " o3: valores vazios totais = 10236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - 1230 valores imputados em 'o3' (≈ 12.0% dos nulos iniciais).\n",
      "\n",
      " pm10: valores vazios totais = 6012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - 790 valores imputados em 'pm10' (≈ 13.1% dos nulos iniciais).\n",
      "\n",
      " pm2_5: valores vazios totais = 113976\n",
      "   - 0 valores imputados em 'pm2_5' (≈ 0.0% dos nulos iniciais).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2155526490.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_interp_if_short_gaps)\n"
     ]
    }
   ],
   "source": [
    "MAX_NULOS_DIA = 6  # até 6 horas vazias no dia pode interpolar\n",
    "\n",
    "# Garante ordenação temporal\n",
    "df = df.sort_values('data').reset_index(drop=True)\n",
    "\n",
    "for col in cols_to_interp:\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "\n",
    "    # Quantidade total de valores vazios na coluna\n",
    "    total_nulos = int(df[col].isna().sum())\n",
    "    print(f\"\\n {col}: valores vazios totais = {total_nulos}\")\n",
    "\n",
    "    # Criar coluna auxiliar com a contagem de nulos por dia (repetida em cada linha do dia)\n",
    "    aux_name = f\"{col}_nulos_no_dia\"\n",
    "    df[aux_name] = (\n",
    "        df[col].isna()\n",
    "          .groupby(df['data_dia'])\n",
    "          .transform('sum')\n",
    "    )\n",
    "\n",
    "    # Aplicar por dia apenas quando nulos_dia <= MAX_NULOS_DIA\n",
    "    def _interp_if_short_gaps(g):\n",
    "        missing = int(g[col].isna().sum())\n",
    "        if 0 < missing <= MAX_NULOS_DIA:\n",
    "            s = (\n",
    "                g.set_index('data')[col]\n",
    "                 .interpolate(method='time', limit_direction='both')\n",
    "            )\n",
    "            g[col] = s.values\n",
    "        return g\n",
    "\n",
    "    before_impute_nulls = int(df[col].isna().sum())\n",
    "    df = (\n",
    "        df.groupby('data_dia', group_keys=False)\n",
    "          .apply(_interp_if_short_gaps)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "    after_impute_nulls = int(df[col].isna().sum())\n",
    "    filled = before_impute_nulls - after_impute_nulls\n",
    "\n",
    "    perc = (100.0 * filled / total_nulos) if total_nulos > 0 else 0.0\n",
    "    print(f\"   - {filled} valores imputados em '{col}' (≈ {perc:.1f}% dos nulos iniciais).\")\n",
    "\n",
    "    # Remover a coluna auxiliar\n",
    "    df.drop(columns=[aux_name], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7adb11c",
   "metadata": {},
   "source": [
    "## Plausibilidade física e outliers extremos  \n",
    "**Por quê?** Sensores podem registrar leituras impossíveis (erros, panes).  \n",
    "Definimos **limites amplos** para marcar valores absurdos como `NaN` (não capamos por padrão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6d838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp: Nenhum valor fora dos limites plausíveis\n",
      "ur: Nenhum valor fora dos limites plausíveis\n",
      "chuva: +5 valores marcados como NaN por plausibilidade\n",
      "co: Nenhum valor fora dos limites plausíveis\n",
      "no: Nenhum valor fora dos limites plausíveis\n",
      "no2: Nenhum valor fora dos limites plausíveis\n",
      "nox: Nenhum valor fora dos limites plausíveis\n",
      "so2: Nenhum valor fora dos limites plausíveis\n",
      "o3: Nenhum valor fora dos limites plausíveis\n",
      "pm10: Nenhum valor fora dos limites plausíveis\n",
      "pm2_5: Nenhum valor fora dos limites plausíveis\n"
     ]
    }
   ],
   "source": [
    "bounds = {\n",
    "    # Meteorologia\n",
    "    'temp': (-5, 55),          # °C\n",
    "    'ur': (0, 100),            # %\n",
    "    'chuva': (0, 200),         # mm (acum. horário; alto para extremos)\n",
    "\n",
    "    # Poluentes — ppm\n",
    "    'co': (0, 50),             # ppm\n",
    "\n",
    "    # Poluentes — µg/m³\n",
    "    'no': (0, 2000),\n",
    "    'no2': (0, 1000),\n",
    "    'nox': (0, 2500),\n",
    "    'so2': (0, 2000),\n",
    "    'o3': (0, 1000),\n",
    "    'pm10': (0, 1000),\n",
    "    'pm2_5': (0, 1000),\n",
    "}\n",
    "\n",
    "df_clean = df.copy()\n",
    "for col, (lo, hi) in bounds.items():\n",
    "    if col in df_clean.columns:\n",
    "        out_before = df_clean[col].isna().sum()\n",
    "        df_clean.loc[(df_clean[col] < lo) | (df_clean[col] > hi), col] = np.nan\n",
    "        out_after = df_clean[col].isna().sum()\n",
    "        if out_after > out_before:\n",
    "            print(f\"{col}: +{out_after - out_before} valores marcados como NaN por plausibilidade\")\n",
    "        else:\n",
    "            print(f\"{col}: Nenhum valor fora dos limites plausíveis\")\n",
    "\n",
    "dup_cols = [c for c in ['nome_estacao','data'] if c in df_clean.columns]\n",
    "if dup_cols:\n",
    "    df_clean = df_clean.drop_duplicates(subset=dup_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c1d91",
   "metadata": {},
   "source": [
    "## Estatísticas descritivas por coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dadb2187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nome_estacao</th>\n",
       "      <td>113976</td>\n",
       "      <td>1</td>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>113976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codnum</th>\n",
       "      <td>113976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>113976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-02 12:00:00</td>\n",
       "      <td>2012-01-01 00:30:00</td>\n",
       "      <td>2015-04-02 06:15:00</td>\n",
       "      <td>2018-07-02 12:00:00</td>\n",
       "      <td>2021-10-01 17:45:00</td>\n",
       "      <td>2024-12-31 23:30:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ano</th>\n",
       "      <td>113976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>3.742349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mes</th>\n",
       "      <td>113976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.522215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.448914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dia</th>\n",
       "      <td>113976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.731733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.801016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_dia</th>\n",
       "      <td>113976</td>\n",
       "      <td>4749</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chuva</th>\n",
       "      <td>108457.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.04</td>\n",
       "      <td>2.169855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>107386.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.828252</td>\n",
       "      <td>11.32</td>\n",
       "      <td>20.68</td>\n",
       "      <td>23.92</td>\n",
       "      <td>28.02</td>\n",
       "      <td>49.16</td>\n",
       "      <td>5.721383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ur</th>\n",
       "      <td>107249.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.009346</td>\n",
       "      <td>10.33</td>\n",
       "      <td>51.67</td>\n",
       "      <td>66.88</td>\n",
       "      <td>79.17</td>\n",
       "      <td>99.91</td>\n",
       "      <td>19.084087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>83763.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.424736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.54</td>\n",
       "      <td>12.08</td>\n",
       "      <td>0.258733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>81055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.504725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>8.8</td>\n",
       "      <td>17.155</td>\n",
       "      <td>253.92</td>\n",
       "      <td>15.507437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no2</th>\n",
       "      <td>81167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.195888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.73</td>\n",
       "      <td>35.13</td>\n",
       "      <td>51.885</td>\n",
       "      <td>235.93</td>\n",
       "      <td>23.55326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nox</th>\n",
       "      <td>81180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.539143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.64</td>\n",
       "      <td>45.55</td>\n",
       "      <td>68.33</td>\n",
       "      <td>418.47</td>\n",
       "      <td>33.915799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>so2</th>\n",
       "      <td>80393.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.753669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.105</td>\n",
       "      <td>4.33</td>\n",
       "      <td>159.82</td>\n",
       "      <td>5.633307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3</th>\n",
       "      <td>104970.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.16717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.24</td>\n",
       "      <td>25.04</td>\n",
       "      <td>41.48</td>\n",
       "      <td>295.49</td>\n",
       "      <td>24.525873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm10</th>\n",
       "      <td>108754.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.917879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>18.235827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm2_5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>113976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lon</th>\n",
       "      <td>113976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>-43.232657</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count unique             top    freq                 mean  \\\n",
       "nome_estacao    113976      1  ESTAÇÃO TIJUCA  113976                  NaN   \n",
       "codnum        113976.0    NaN             NaN     NaN                  8.0   \n",
       "data            113976    NaN             NaN     NaN  2018-07-02 12:00:00   \n",
       "ano           113976.0    NaN             NaN     NaN               2018.0   \n",
       "mes           113976.0    NaN             NaN     NaN             6.522215   \n",
       "dia           113976.0    NaN             NaN     NaN            15.731733   \n",
       "data_dia        113976   4749      2012-01-01      24                  NaN   \n",
       "chuva         108457.0    NaN             NaN     NaN             0.144681   \n",
       "temp          107386.0    NaN             NaN     NaN            24.828252   \n",
       "ur            107249.0    NaN             NaN     NaN            65.009346   \n",
       "co             83763.0    NaN             NaN     NaN             0.424736   \n",
       "no             81055.0    NaN             NaN     NaN            13.504725   \n",
       "no2            81167.0    NaN             NaN     NaN            39.195888   \n",
       "nox            81180.0    NaN             NaN     NaN            52.539143   \n",
       "so2            80393.0    NaN             NaN     NaN             3.753669   \n",
       "o3            104970.0    NaN             NaN     NaN             30.16717   \n",
       "pm10          108754.0    NaN             NaN     NaN            31.917879   \n",
       "pm2_5              0.0    NaN             NaN     NaN                  NaN   \n",
       "lat           113976.0    NaN             NaN     NaN           -22.924915   \n",
       "lon           113976.0    NaN             NaN     NaN           -43.232657   \n",
       "\n",
       "                              min                  25%                  50%  \\\n",
       "nome_estacao                  NaN                  NaN                  NaN   \n",
       "codnum                        8.0                  8.0                  8.0   \n",
       "data          2012-01-01 00:30:00  2015-04-02 06:15:00  2018-07-02 12:00:00   \n",
       "ano                        2012.0               2015.0               2018.0   \n",
       "mes                           1.0                  4.0                  7.0   \n",
       "dia                           1.0                  8.0                 16.0   \n",
       "data_dia                      NaN                  NaN                  NaN   \n",
       "chuva                         0.0                  0.0                  0.0   \n",
       "temp                        11.32                20.68                23.92   \n",
       "ur                          10.33                51.67                66.88   \n",
       "co                            0.0                 0.26                 0.39   \n",
       "no                            0.0                 4.07                  8.8   \n",
       "no2                           0.0                21.73                35.13   \n",
       "nox                           0.0                28.64                45.55   \n",
       "so2                           0.0                 0.82                2.105   \n",
       "o3                            0.0                12.24                25.04   \n",
       "pm10                          0.0                 20.0                 28.0   \n",
       "pm2_5                         NaN                  NaN                  NaN   \n",
       "lat                    -22.924915           -22.924915           -22.924915   \n",
       "lon                    -43.232657           -43.232657           -43.232657   \n",
       "\n",
       "                              75%                  max        std  \n",
       "nome_estacao                  NaN                  NaN        NaN  \n",
       "codnum                        8.0                  8.0        0.0  \n",
       "data          2021-10-01 17:45:00  2024-12-31 23:30:00        NaN  \n",
       "ano                        2021.0               2024.0   3.742349  \n",
       "mes                          10.0                 12.0   3.448914  \n",
       "dia                          23.0                 31.0   8.801016  \n",
       "data_dia                      NaN                  NaN        NaN  \n",
       "chuva                         0.0               197.04   2.169855  \n",
       "temp                        28.02                49.16   5.721383  \n",
       "ur                          79.17                99.91  19.084087  \n",
       "co                           0.54                12.08   0.258733  \n",
       "no                         17.155               253.92  15.507437  \n",
       "no2                        51.885               235.93   23.55326  \n",
       "nox                         68.33               418.47  33.915799  \n",
       "so2                          4.33               159.82   5.633307  \n",
       "o3                          41.48               295.49  24.525873  \n",
       "pm10                         40.0                310.0  18.235827  \n",
       "pm2_5                         NaN                  NaN        NaN  \n",
       "lat                    -22.924915           -22.924915        0.0  \n",
       "lon                    -43.232657           -43.232657        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "desc = df_clean.describe(include='all').T\n",
    "desc.to_csv(DATA_DIR / f\"estatisticas_{ESTACAO}.csv\")\n",
    "display(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f2b4ef",
   "metadata": {},
   "source": [
    "## Séries temporais e médias móveis (7 e 30 dias)\n",
    "Gera gráficos individuais por variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b993cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series_with_roll(df_, col, outdir):\n",
    "    if col not in df_.columns:\n",
    "        return\n",
    "    s = df_.set_index('data')[col].sort_index()\n",
    "    if s.dropna().empty:\n",
    "        return\n",
    "    rm7 = s.rolling('7D').mean()\n",
    "    rm30 = s.rolling('30D').mean()\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    s.plot(linewidth=0.8, label=col)\n",
    "    rm7.plot(linewidth=1.0, label='mm7')\n",
    "    rm30.plot(linewidth=1.2, label='mm30')\n",
    "    plt.title(f\"{col} — Série horária e médias móveis\")\n",
    "    plt.xlabel(\"Tempo\")\n",
    "    plt.ylabel(col)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"serie.png\", dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5d931",
   "metadata": {},
   "source": [
    "## Distribuições: histograma e boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48fc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(df_, col, outdir):\n",
    "    if col not in df_.columns:\n",
    "        return\n",
    "    x = df_[col].dropna()\n",
    "    if x.empty:\n",
    "        return\n",
    "\n",
    "    # Histograma\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(x, bins=40)\n",
    "    plt.title(f\"Histograma — {col}\")\n",
    "    plt.xlabel(col); plt.ylabel(\"Frequência\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"hist.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # Boxplot\n",
    "    plt.figure(figsize=(4,5))\n",
    "    plt.boxplot(x.values, vert=True)\n",
    "    plt.title(f\"Boxplot — {col}\")\n",
    "    plt.ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"box.png\", dpi=150)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441a5d3",
   "metadata": {},
   "source": [
    "## Sazonalidade: perfis mensais e anuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95c06126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_profile(df_, col, outdir):\n",
    "    if col not in df_.columns:\n",
    "        return\n",
    "    tmp = df_[['mes', col]].copy()\n",
    "    g = tmp.groupby('mes')[col].mean(numeric_only=True)\n",
    "    if g.dropna().empty:\n",
    "        return\n",
    "    plt.figure(figsize=(8,3.5))\n",
    "    plt.plot(g.index, g.values, marker='o')\n",
    "    plt.title(f\"Média mensal — {col}\")\n",
    "    plt.xlabel(\"Mês\"); plt.ylabel(col)\n",
    "    plt.xticks(range(1,13))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"mensal.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def yearly_profile(df_, col, outdir):\n",
    "    if col not in df_.columns:\n",
    "        return\n",
    "    tmp = df_[['ano', col]].copy()\n",
    "    g = tmp.groupby('ano')[col].mean(numeric_only=True)\n",
    "    if g.dropna().empty:\n",
    "        return\n",
    "    plt.figure(figsize=(8,3.5))\n",
    "    plt.plot(g.index, g.values, marker='o')\n",
    "    plt.title(f\"Média anual — {col}\")\n",
    "    plt.xlabel(\"Ano\"); plt.ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"anual.png\", dpi=150)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c226f71",
   "metadata": {},
   "source": [
    "## Gerando figuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35438f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figuras salvas por coluna em subpastas de: resultados_estacao_TIJUCA\\figuras\n"
     ]
    }
   ],
   "source": [
    "for c in cols_to_interp:\n",
    "    col_dir = _col_dir(FIG_DIR, c)\n",
    "    plot_series_with_roll(df_clean, c, col_dir)\n",
    "    plot_distributions(df_clean, c, col_dir)\n",
    "    monthly_profile(df_clean, c, col_dir)\n",
    "    yearly_profile(df_clean, c, col_dir)\n",
    "\n",
    "print(\"Figuras salvas por coluna em subpastas de:\", FIG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65b874f",
   "metadata": {},
   "source": [
    "## Salvando tratamento por hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ebb298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: C:\\Users\\jhter\\OneDrive - cefet-rj.br\\25_2-QualiAr\\data\\DataRio\\Estacoes_Tratadas_Por_Hora\\ESTACAO_TIJUCA_POR_HORA.csv\n"
     ]
    }
   ],
   "source": [
    "project_root = Path().resolve().parents[2]    \n",
    "\n",
    "output_dir = project_root / \"data\" / \"DataRio\" / \"Estacoes_Tratadas_Por_Hora\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_csv_path = output_dir / f\"ESTACAO_{ESTACAO}_POR_HORA.csv\"\n",
    "df_clean.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Arquivo salvo em: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1535b547",
   "metadata": {},
   "source": [
    "## Criando nova feature (AQI)\n",
    "\n",
    "https://jeap.rio.rj.gov.br/je-metinfosmac/boletim\n",
    "\n",
    "Como calcular o AQI\n",
    "https://airly.org/en/air-quality-index-caqi-and-aqi-methods-of-calculation/\n",
    "\n",
    "| MP₁₀ (µg/m³) 24h | MP₂.₅ (µg/m³) 24h | O₃ (µg/m³) 8h | CO (ppm) 8h | NO₂ (µg/m³) 1h | SO₂ (µg/m³) 24h | Índice | Qualidade do Ar | Efeitos |\n",
    "|------------------|------------------|---------------|-------------|----------------|------------------|--------|------------------|---------|\n",
    "| 0 - 50           | 0 - 25           | 0 - 100       | 0 - 9       | 0 - 200        | 0 - 20           | 0 - 40 | N1 - Boa         | - |\n",
    "| >50 - 100        | >25 - 50         | >100 - 130    | >9 - 11     | >200 - 240     | >20 - 40         | 41 - 80 | N2 - Moderada     | Pessoas de grupos sensíveis (crianças, idosos e pessoas com doenças respiratórias e cardíacas) podem apresentar sintomas como tosse seca e cansaço. A população em geral não é afetada. |\n",
    "| >100 - 150       | >50 - 75         | >130 - 160    | >11 - 13    | >240 - 320     | >40 - 365        | 81 - 120 | N3 - Ruim         | Toda a população pode apresentar sintomas como tosse seca, cansaço, ardor nos olhos, nariz e garganta. Pessoas de grupos sensíveis (crianças, idosos e pessoas com doenças respiratórias e cardíacas) podem apresentar efeitos mais sérios na saúde. |\n",
    "| >150 - 250       | >75 - 125        | >160 - 200    | >13 - 15    | >320 - 1130    | >365 - 800       | 121 - 200 | N4 - Muito Ruim   | Toda a população pode apresentar agravamento dos sintomas como tosse seca, cansaço, ardor nos olhos, nariz e garganta e ainda falta de ar e respiração ofegante. Efeitos ainda mais graves à saúde de grupos sensíveis (crianças, idosos e pessoas com doenças respiratórias e cardíacas). |\n",
    "| >250 - 600       | >125 - 300       | >200 - 800    | >15 - 50    | >1130 - 3750   | >800 - 2620      | 201 - 400 | N5 - Péssima      | Toda a população pode apresentar sérios riscos de manifestações de doenças respiratórias e cardiovasculares. Aumento de mortes prematuras em pessoas de grupos sensíveis. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706c0f58",
   "metadata": {},
   "source": [
    "### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f67525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREAKPOINTS = {\n",
    "    \"pm10_24h\": [\n",
    "        (0, 50, 0, 40),\n",
    "        (50, 100, 41, 80),\n",
    "        (100, 150, 81, 120),\n",
    "        (150, 250, 121, 200),\n",
    "        (250, 600, 201, 400),\n",
    "    ],\n",
    "    \"pm2_5_24h\": [\n",
    "        (0, 25, 0, 40),\n",
    "        (25, 50, 41, 80),\n",
    "        (50, 75, 81, 120),\n",
    "        (75, 125, 121, 200),\n",
    "        (125, 300, 201, 400),\n",
    "    ],\n",
    "    \"o3_8h\": [\n",
    "        (0, 100, 0, 40),\n",
    "        (100, 130, 41, 80),\n",
    "        (130, 160, 81, 120),\n",
    "        (160, 200, 121, 200),\n",
    "        (200, 800, 201, 400),\n",
    "    ],\n",
    "    \"co_8h\": [\n",
    "        (0, 9, 0, 40),\n",
    "        (9, 11, 41, 80),\n",
    "        (11, 13, 81, 120),\n",
    "        (13, 15, 121, 200),\n",
    "        (15, 50, 201, 400),\n",
    "    ],\n",
    "    \"no2_1h\": [\n",
    "        (0, 200, 0, 40),\n",
    "        (200, 240, 41, 80),\n",
    "        (240, 320, 81, 120),\n",
    "        (320, 1130, 121, 200),\n",
    "        (1130, 3750, 201, 400),\n",
    "    ],\n",
    "    \"so2_24h\": [\n",
    "        (0, 20, 0, 40),\n",
    "        (20, 40, 41, 80),\n",
    "        (40, 365, 81, 120),\n",
    "        (365, 800, 121, 200),\n",
    "        (800, 2620, 201, 400),\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e203c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotulagem do índice\n",
    "def qual_label(idx):\n",
    "    if pd.isna(idx):\n",
    "        return np.nan, np.nan\n",
    "    if 0 <= idx <= 40:\n",
    "        return \"N1 - Boa\", \"-\"\n",
    "    if 41 <= idx <= 80:\n",
    "        return \"N2 - Moderada\", \"Grupos sensíveis podem apresentar sintomas; população geral não afetada.\"\n",
    "    if 81 <= idx <= 120:\n",
    "        return \"N3 - Ruim\", \"Sintomas em toda a população; grupos sensíveis podem ter efeitos mais sérios.\"\n",
    "    if 121 <= idx <= 200:\n",
    "        return \"N4 - Muito Ruim\", \"Agravamento de sintomas na população; efeitos mais graves em grupos sensíveis.\"\n",
    "    if 201 <= idx <= 400:\n",
    "        return \"N5 - Péssima\", \"Riscos sérios à saúde; aumento de mortes prematuras em grupos sensíveis.\"\n",
    "    # Fora da escala\n",
    "    return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f88fc707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do subíndice por interpolação linear dentro da faixa\n",
    "def calc_subindex(metric_name, concentration):\n",
    "    if pd.isna(concentration):\n",
    "        return np.nan\n",
    "    for (c_lo, c_hi, i_lo, i_hi) in BREAKPOINTS[metric_name]:\n",
    "        # inclui limite inferior, exclui superior (última faixa inclui ambos)\n",
    "        if (concentration >= c_lo) and (concentration < c_hi or (concentration == c_hi and (c_hi == BREAKPOINTS[metric_name][-1][0] or (c_hi, i_hi) == BREAKPOINTS[metric_name][-1][0:2]))):\n",
    "            # interpolação linear\n",
    "            if c_hi == c_lo: \n",
    "                return float(i_hi)\n",
    "            return float(i_lo + (i_hi - i_lo) * (concentration - c_lo) / (c_hi - c_lo))\n",
    "    # Acima do último breakpoint: extrapola linearmente na última faixa\n",
    "    c_lo, c_hi, i_lo, i_hi = BREAKPOINTS[metric_name][-1]\n",
    "    if concentration > c_hi:\n",
    "        return float(i_lo + (i_hi - i_lo) * (concentration - c_lo) / (c_hi - c_lo))\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71b9905",
   "metadata": {},
   "source": [
    "### Leitura e preparo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "412afaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\3756843583.py:2: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[\"data\"] = pd.to_datetime(df[\"data\"], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome_estacao</th>\n",
       "      <th>codnum</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>data_dia</th>\n",
       "      <th>chuva</th>\n",
       "      <th>temp</th>\n",
       "      <th>ur</th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>nox</th>\n",
       "      <th>so2</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:30:00</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.62</td>\n",
       "      <td>88.31</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "      <td>24.71</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:30:00</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>23.50</td>\n",
       "      <td>93.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:30:00</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.51</td>\n",
       "      <td>98.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>19.22</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:30:00</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>98.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.51</td>\n",
       "      <td>24.55</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:30:00</th>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21.36</td>\n",
       "      <td>98.41</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>19.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.924915</td>\n",
       "      <td>-43.232657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nome_estacao  codnum   ano  mes  dia    data_dia  \\\n",
       "data                                                                      \n",
       "2012-01-01 00:30:00  ESTAÇÃO TIJUCA       8  2012    1    1  2012-01-01   \n",
       "2012-01-01 01:30:00  ESTAÇÃO TIJUCA       8  2012    1    1  2012-01-01   \n",
       "2012-01-01 02:30:00  ESTAÇÃO TIJUCA       8  2012    1    1  2012-01-01   \n",
       "2012-01-01 03:30:00  ESTAÇÃO TIJUCA       8  2012    1    1  2012-01-01   \n",
       "2012-01-01 04:30:00  ESTAÇÃO TIJUCA       8  2012    1    1  2012-01-01   \n",
       "\n",
       "                     chuva   temp     ur    co  no  no2  nox   so2     o3  \\\n",
       "data                                                                        \n",
       "2012-01-01 00:30:00    0.0  24.62  88.31  0.07 NaN  NaN  NaN  0.36  24.71   \n",
       "2012-01-01 01:30:00    0.4  23.50  93.05  0.11 NaN  NaN  NaN  0.28  22.74   \n",
       "2012-01-01 02:30:00    1.0  22.51  98.06  0.10 NaN  NaN  NaN  0.27  19.22   \n",
       "2012-01-01 03:30:00    0.0  21.47  98.40  0.06 NaN  NaN  NaN  1.51  24.55   \n",
       "2012-01-01 04:30:00    0.2  21.36  98.41  0.08 NaN  NaN  NaN  1.89  19.00   \n",
       "\n",
       "                     pm10  pm2_5        lat        lon  \n",
       "data                                                    \n",
       "2012-01-01 00:30:00  27.0    NaN -22.924915 -43.232657  \n",
       "2012-01-01 01:30:00  28.0    NaN -22.924915 -43.232657  \n",
       "2012-01-01 02:30:00  28.0    NaN -22.924915 -43.232657  \n",
       "2012-01-01 03:30:00  36.0    NaN -22.924915 -43.232657  \n",
       "2012-01-01 04:30:00  40.0    NaN -22.924915 -43.232657  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df_clean.copy()\n",
    "df[\"data\"] = pd.to_datetime(df[\"data\"], errors=\"coerce\", infer_datetime_format=True)\n",
    "df = df.sort_values(\"data\").set_index(\"data\")\n",
    "\n",
    "# Garantir nomes esperados\n",
    "colmap = {\n",
    "    \"pm10\": \"pm10\",\n",
    "    \"pm2_5\": \"pm2_5\",\n",
    "    \"o3\": \"o3\",\n",
    "    \"co\": \"co\",\n",
    "    \"no2\": \"no2\",\n",
    "    \"so2\": \"so2\",\n",
    "}\n",
    "for c in colmap.values():\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        \n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27e36e",
   "metadata": {},
   "source": [
    "### Cálculo das métricas diárias\n",
    "Regras:\n",
    "- PM10 24h: média diária (requer cobertura mínima de horas)\n",
    "- PM2.5 24h: média diária\n",
    "- SO2 24h: média diária\n",
    "- O3 8h: maior média móvel de 8h dentro do dia\n",
    "- CO 8h: maior média móvel de 8h dentro do dia\n",
    "- NO2 1h: máximo horário do dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dced69ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhter\\AppData\\Local\\Temp\\ipykernel_27708\\2103729125.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  roll = series.rolling(\"8H\", min_periods=min_hours).mean()\n"
     ]
    }
   ],
   "source": [
    "MIN_HORAS_24H = 18   # cobertura mínima para considerar o dia em médias 24h\n",
    "MIN_HORAS_8H = 6     # cobertura mínima dentro da janela de 8h\n",
    "\n",
    "# 24h means with coverage\n",
    "def daily_mean_with_min(series, min_hours=MIN_HORAS_24H):\n",
    "    grp = series.resample(\"D\").agg([\"mean\", \"count\"])\n",
    "    out = grp[\"mean\"].where(grp[\"count\"] >= min_hours)\n",
    "    return out\n",
    "\n",
    "pm10_24h = daily_mean_with_min(df[\"pm10\"]) if \"pm10\" in df.columns else pd.Series(dtype=float)\n",
    "pm2_5_24h = daily_mean_with_min(df[\"pm2_5\"]) if \"pm2_5\" in df.columns else pd.Series(dtype=float)\n",
    "so2_24h = daily_mean_with_min(df[\"so2\"]) if \"so2\" in df.columns else pd.Series(dtype=float)\n",
    "\n",
    "# 8h rolling max within day\n",
    "def daily_8h_max(series, min_hours=MIN_HORAS_8H):\n",
    "    if series.name is None:\n",
    "        series = series.copy()\n",
    "        series.name = \"x\"\n",
    "    roll = series.rolling(\"8H\", min_periods=min_hours).mean()\n",
    "    return roll.resample(\"D\").max()\n",
    "\n",
    "o3_8h_max = daily_8h_max(df[\"o3\"]) if \"o3\" in df.columns else pd.Series(dtype=float)\n",
    "co_8h_max = daily_8h_max(df[\"co\"]) if \"co\" in df.columns else pd.Series(dtype=float)\n",
    "\n",
    "# NO2 1h max per day\n",
    "no2_1h_max = df[\"no2\"].resample(\"D\").max() if \"no2\" in df.columns else pd.Series(dtype=float)\n",
    "\n",
    "# ===== SUBÍNDICES POR POLUENTE =====\n",
    "out = pd.DataFrame(index=df.resample(\"D\").size().index)\n",
    "out.index.name = \"data_dia\"\n",
    "\n",
    "# Guardar métricas\n",
    "if not pm10_24h.empty:  out[\"pm10_24h\"] = pm10_24h\n",
    "if not pm2_5_24h.empty: out[\"pm2_5_24h\"] = pm2_5_24h\n",
    "if not so2_24h.empty:   out[\"so2_24h\"] = so2_24h\n",
    "if not o3_8h_max.empty: out[\"o3_8h\"] = o3_8h_max\n",
    "if not co_8h_max.empty: out[\"co_8h\"] = co_8h_max\n",
    "if not no2_1h_max.empty:out[\"no2_1h\"] = no2_1h_max\n",
    "\n",
    "# Subíndices (interpolados nas faixas)\n",
    "if \"pm10_24h\" in out:\n",
    "    out[\"idx_pm10\"] = out[\"pm10_24h\"].apply(lambda v: calc_subindex(\"pm10_24h\", v))\n",
    "if \"pm2_5_24h\" in out:\n",
    "    out[\"idx_pm2_5\"] = out[\"pm2_5_24h\"].apply(lambda v: calc_subindex(\"pm2_5_24h\", v))\n",
    "if \"o3_8h\" in out:\n",
    "    out[\"idx_o3\"] = out[\"o3_8h\"].apply(lambda v: calc_subindex(\"o3_8h\", v))\n",
    "if \"co_8h\" in out:\n",
    "    out[\"idx_co\"] = out[\"co_8h\"].apply(lambda v: calc_subindex(\"co_8h\", v))\n",
    "if \"no2_1h\" in out:\n",
    "    out[\"idx_no2\"] = out[\"no2_1h\"].apply(lambda v: calc_subindex(\"no2_1h\", v))\n",
    "if \"so2_24h\" in out:\n",
    "    out[\"idx_so2\"] = out[\"so2_24h\"].apply(lambda v: calc_subindex(\"so2_24h\", v))\n",
    "\n",
    "# ===== AQI por dia (pior subíndice do dia) =====\n",
    "idx_cols = [c for c in out.columns if c.startswith(\"idx_\")]\n",
    "out[\"AQI\"] = out[idx_cols].max(axis=1, skipna=True).round(0).astype(\"Int64\")\n",
    "\n",
    "# Poluente dominante (o de maior subíndice)\n",
    "def dominante_row(row):\n",
    "    vals = row[idx_cols]\n",
    "    if vals.dropna().empty:\n",
    "        return np.nan\n",
    "    pol = vals.idxmax() # pega o nome do poluente com maior subíndice\n",
    "    return pol.replace(\"idx_\", \"\")\n",
    "\n",
    "out[\"dominante\"] = out.apply(dominante_row, axis=1)\n",
    "\n",
    "# Rotulagem de qualidade e efeitos\n",
    "labels = out[\"AQI\"].apply(qual_label)\n",
    "out[\"Qualidade_do_Ar\"] = labels.apply(lambda x: x[0])\n",
    "out[\"Efeitos\"] = labels.apply(lambda x: x[1])\n",
    "\n",
    "ordered = [\"AQI\", \"Qualidade_do_Ar\"] # \"Efeitos\", \"dominante\"\n",
    "metric_cols = [c for c in [\"pm10_24h\",\"pm2_5_24h\",\"o3_8h\",\"co_8h\",\"no2_1h\",\"so2_24h\"] if c in out.columns]\n",
    "# ordered += metric_cols + idx_cols\n",
    "out = out[ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed882ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQI diário salvo em: C:\\Users\\jhter\\OneDrive - cefet-rj.br\\25_2-QualiAr\\data\\DataRio\\AQI\\AQI_TIJUCA.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = project_root / \"data\" / \"DataRio\" / \"AQI\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_csv_path = output_dir / f\"AQI_{ESTACAO}.csv\"\n",
    "\n",
    "out.reset_index().to_csv(output_csv_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"AQI diário salvo em: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e9bbc2",
   "metadata": {},
   "source": [
    "## Gerando por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a953a5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_dia</th>\n",
       "      <th>nome_estacao</th>\n",
       "      <th>codnum</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>chuva</th>\n",
       "      <th>temp</th>\n",
       "      <th>ur</th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>nox</th>\n",
       "      <th>so2</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>23.226</td>\n",
       "      <td>95.108</td>\n",
       "      <td>0.124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.373</td>\n",
       "      <td>14.330</td>\n",
       "      <td>22.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.925</td>\n",
       "      <td>-43.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.066</td>\n",
       "      <td>98.163</td>\n",
       "      <td>0.264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.998</td>\n",
       "      <td>10.927</td>\n",
       "      <td>15.708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.925</td>\n",
       "      <td>-43.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.855</td>\n",
       "      <td>77.530</td>\n",
       "      <td>0.162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.776</td>\n",
       "      <td>9.933</td>\n",
       "      <td>26.208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.925</td>\n",
       "      <td>-43.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.741</td>\n",
       "      <td>71.502</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.354</td>\n",
       "      <td>19.879</td>\n",
       "      <td>27.458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.925</td>\n",
       "      <td>-43.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>ESTAÇÃO TIJUCA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.865</td>\n",
       "      <td>77.911</td>\n",
       "      <td>0.103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.582</td>\n",
       "      <td>35.781</td>\n",
       "      <td>29.167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.925</td>\n",
       "      <td>-43.233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data_dia    nome_estacao  codnum     ano  mes  dia  chuva    temp  \\\n",
       "0  2012-01-01  ESTAÇÃO TIJUCA     8.0  2012.0  1.0  1.0    5.2  23.226   \n",
       "1  2012-01-02  ESTAÇÃO TIJUCA     8.0  2012.0  1.0  2.0   19.0  20.066   \n",
       "2  2012-01-03  ESTAÇÃO TIJUCA     8.0  2012.0  1.0  3.0    0.0  23.855   \n",
       "3  2012-01-04  ESTAÇÃO TIJUCA     8.0  2012.0  1.0  4.0    0.0  25.741   \n",
       "4  2012-01-05  ESTAÇÃO TIJUCA     8.0  2012.0  1.0  5.0    0.0  25.865   \n",
       "\n",
       "       ur     co  no  no2  nox    so2      o3    pm10  pm2_5     lat     lon  \n",
       "0  95.108  0.124 NaN  NaN  NaN  3.373  14.330  22.375    NaN -22.925 -43.233  \n",
       "1  98.163  0.264 NaN  NaN  NaN  2.998  10.927  15.708    NaN -22.925 -43.233  \n",
       "2  77.530  0.162 NaN  NaN  NaN  5.776   9.933  26.208    NaN -22.925 -43.233  \n",
       "3  71.502  0.171 NaN  NaN  NaN  2.354  19.879  27.458    NaN -22.925 -43.233  \n",
       "4  77.911  0.103 NaN  NaN  NaN  1.582  35.781  29.167    NaN -22.925 -43.233  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = df_clean.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "# Separar chuva das demais\n",
    "rain_cols = [c for c in numeric_cols if \"chuva\" in c.lower()]\n",
    "other_numeric = [c for c in numeric_cols if c not in rain_cols]\n",
    "\n",
    "# Agrupamento\n",
    "daily_df = (\n",
    "    df_clean.groupby(\"data_dia\")\n",
    "    .agg({\n",
    "        \"nome_estacao\": \"first\",\n",
    "        \"codnum\": \"first\",\n",
    "        \"ano\": \"first\",\n",
    "        \"mes\": \"first\",\n",
    "        \"dia\": \"first\",\n",
    "        **{col: \"sum\" for col in rain_cols},      # chuva = soma\n",
    "        **{col: \"mean\" for col in other_numeric}, # demais numéricas = média\n",
    "        \"lat\": \"first\",\n",
    "        \"lon\": \"first\"\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Arredondar colunas numéricas para 3 casas decimais\n",
    "for col in numeric_cols:\n",
    "    if col in daily_df.columns:\n",
    "        daily_df[col] = daily_df[col].round(3)\n",
    "\n",
    "daily_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b500356e",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m aqi = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://raw.githubusercontent.com/EIC-BCC/25_2-QualiAr/refs/heads/main/data/DataRio/AQI/AQI_TIJUCA.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m aqi[\u001b[33m\"\u001b[39m\u001b[33mdata_dia\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(aqi[\u001b[33m\"\u001b[39m\u001b[33mdata_dia\u001b[39m\u001b[33m\"\u001b[39m]).dt.date\n\u001b[32m      5\u001b[39m daily_df = daily_df.merge(aqi, on=\u001b[33m\"\u001b[39m\u001b[33mdata_dia\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhter\\OneDrive - cefet-rj.br\\25_2-QualiAr\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhter\\OneDrive - cefet-rj.br\\25_2-QualiAr\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhter\\OneDrive - cefet-rj.br\\25_2-QualiAr\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhter\\OneDrive - cefet-rj.br\\25_2-QualiAr\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhter\\OneDrive - cefet-rj.br\\25_2-QualiAr\\venv\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhter\\OneDrive - cefet-rj.br\\25_2-QualiAr\\venv\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhter\\OneDrive - cefet-rj.br\\25_2-QualiAr\\venv\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:521\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    520\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:630\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:559\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    558\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:639\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "aqi = pd.read_csv('https://raw.githubusercontent.com/EIC-BCC/25_2-QualiAr/refs/heads/main/data/DataRio/AQI/AQI_TIJUCA.csv')\n",
    "\n",
    "aqi[\"data_dia\"] = pd.to_datetime(aqi[\"data_dia\"]).dt.date\n",
    "\n",
    "daily_df = daily_df.merge(aqi, on=\"data_dia\", how=\"left\")\n",
    "\n",
    "int_cols = [\"codnum\", \"ano\", \"mes\", \"dia\", \"AQI\"]\n",
    "\n",
    "for col in int_cols:\n",
    "    if col in daily_df.columns:\n",
    "        daily_df[col] = daily_df[col].astype(\"Int64\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbb14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4749, 23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(daily_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: C:\\Users\\jhter\\OneDrive - cefet-rj.br\\qualiar\\data\\DataRio\\Estacoes_Tratadas_Por_Dia\\ESTACAO_TIJUCA_POR_DIA.csv\n"
     ]
    }
   ],
   "source": [
    "project_root = Path().resolve().parents[2]    \n",
    "\n",
    "output_dir = project_root / \"data\" / \"DataRio\" / \"Estacoes_Tratadas_Por_Dia\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_csv_path = output_dir / f\"ESTACAO_{ESTACAO}_POR_DIA.csv\"\n",
    "daily_df.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Arquivo salvo em: {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
